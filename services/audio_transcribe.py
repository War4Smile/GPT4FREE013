# services/audio_transcribe.py
import os
import base64
import logging
import tempfile
import config
from datetime import datetime
from aiogram import F, Router
from aiogram.enums import ParseMode, ChatAction
from aiogram.filters import Command
from aiogram.types import Message
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from utils.helpers import is_admin, save_users
from services.tgapi import bot
from database import (  save_users, load_users, save_blocked_users,
                        user_history, user_settings, user_info,
                        image_requests, last_image_requests,
                        user_states, admin_states, blocked_users,
                        user_analysis_states, user_analysis_settings,
                        user_transcribe_states)
from utils.helpers import ( get_user_settings, convert_to_mp3, split_audio,
                            encode_audio_base64, remove_html_tags,
                            auto_detect_language, format_response)
from services.retry import (transcribe_with_retry, download_image_with_retry,
                            generate_audio_with_retry)

router = Router()

class AudioState(StatesGroup):
    waiting_for_audio = State()

###########################################################
##### –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ Polinations ##### 

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /transcribe
@router.message(Command("transcribe"))
async def cmd_transcribe(message: Message):
    user_id = message.from_user.id
    await message.answer("üé§ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.")
    user_transcribe_states[user_id] = "waiting_for_audio_transcribe"

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
@router.message(lambda message: message.audio or message.voice or message.document and message.document.mime_type.startswith('audio/'))
async def handle_audio_transcribe(message: Message):
    user_id = message.from_user.id
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ–∂–∏–¥–∞–µ–º –ª–∏ –º—ã –∞—É–¥–∏–æ—Ñ–∞–π–ª –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    if user_transcribe_states.get(user_id) != "waiting_for_audio_transcribe":
        return  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º, –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–ª–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
    
    await bot.send_chat_action(message.chat.id, ChatAction.TYPING)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
        audio_file = message.audio or message.voice or message.document
        file_info = await bot.get_file(audio_file.file_id)
        file_path = file_info.file_path
        
        # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        temp_dir = tempfile.gettempdir()
        temp_input_path = os.path.join(temp_dir, f"{file_info.file_id}.{file_path.split('.')[-1]}")
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        await bot.download_file(file_path, temp_input_path)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        file_extension = temp_input_path.split('.')[-1].lower()
        if file_extension not in config.SUPPORTED_AUDIO_FORMATS:
            await message.answer(f"‚ùå –§–æ—Ä–º–∞—Ç {file_extension} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: {', '.join(config.SUPPORTED_AUDIO_FORMATS)}")
            return
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        file_size = os.path.getsize(temp_input_path)
        if file_size > config.MAX_AUDIO_SIZE:
            await message.answer("‚è≥ –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ü–æ–ø—Ä–æ–±—É—é —Å–∂–∞—Ç—å...")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ MP3
            mp3_path = os.path.join(temp_dir, f"{file_info.file_id}.mp3")
            
            if not convert_to_mp3(temp_input_path, mp3_path):
                await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª –≤ MP3")
                return
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            mp3_size = os.path.getsize(mp3_path)
            if mp3_size > config.MAX_AUDIO_SIZE:
                await message.answer("‚è≥ –§–∞–π–ª –≤—Å—ë –µ—â—ë —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –†–∞–∑–±–∏–≤–∞—é –Ω–∞ —á–∞—Å—Ç–∏...")
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
                chunks = split_audio(mp3_path)
                if not chunks:
                    await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–∞ —á–∞—Å—Ç–∏")
                    return
                
                full_transcription = ""
                progress_msg = await message.answer("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–µ–π —Ñ–∞–π–ª–∞:")
                
                for i, chunk_path in enumerate(chunks):
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                    await progress_msg.edit_text(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–∏ {i+1}/{len(chunks)}")
                    
                    # –ö–æ–¥–∏—Ä—É–µ–º —á–∞—Å—Ç—å –≤ base64
                    with open(chunk_path, "rb") as f:
                        encoded_audio = base64.b64encode(f.read()).decode('utf-8')
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ API
                    payload = {
                        "model": config.TRANSCRIBE_MODEL,
                        "messages": [
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å–ø–æ–∑–Ω–∞–π—Ç–µ —Ä–µ—á—å –∏–∑ —ç—Ç–æ–π —á–∞—Å—Ç–∏ —Ñ–∞–π–ª–∞:"},
                                    {
                                        "type": "input_audio",
                                        "input_audio": {
                                            "data": encoded_audio,
                                            "format": "mp3"
                                        }
                                    }
                                ]
                            }
                        ]
                    }
                    
                    try:
                        result = await transcribe_with_retry(payload)
                        transcription = result['choices'][0]['message']['content']
                        full_transcription += f"–ß–∞—Å—Ç—å {i+1}:\n{transcription}\n\n"
                    except Exception as e:
                        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ —á–∞—Å—Ç–∏ {i+1}: {str(e)}")
                        full_transcription += f"–ß–∞—Å—Ç—å {i+1}: –û–®–ò–ë–ö–ê - {str(e)}\n\n"
                
                # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                await progress_msg.delete()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                user_entry = {
                    "type": "transcribe",
                    "prompt": "–†–∞—Å–ø–æ–∑–Ω–∞–π—Ç–µ —Ä–µ—á—å –∏–∑ —ç—Ç–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (—Ä–∞–∑–±–∏—Ç –Ω–∞ —á–∞—Å—Ç–∏)",
                    "timestamp": datetime.now().isoformat()
                }
                user_history.setdefault(user_id, []).append(user_entry)
                
                assistant_entry = {
                    "type": "transcribe",
                    "response": full_transcription,
                    "timestamp": datetime.now().isoformat()
                }
                user_history[user_id].append(assistant_entry)
                save_users()
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                await message.answer(f"üé§ –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (—Ñ–∞–π–ª —Ä–∞–∑–±–∏—Ç –Ω–∞ —á–∞—Å—Ç–∏):\n\n{full_transcription}")
                return
        
        else:
            # –§–∞–π–ª –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
            with open(temp_input_path, "rb") as f:
                encoded_audio = base64.b64encode(f.read()).decode('utf-8')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ API
        payload = {
            "model": config.TRANSCRIBE_MODEL,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞—Å–ø–æ–∑–Ω–∞–π—Ç–µ —Ä–µ—á—å –∏–∑ —ç—Ç–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞:"},
                        {
                            "type": "input_audio",
                            "input_audio": {
                                "data": encoded_audio,
                                "format": file_extension
                            }
                        }
                    ]
                }
            ]
        }
        
        logging.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ –æ—Ç {user_id}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        result = await transcribe_with_retry(payload)
        transcription = result['choices'][0]['message']['content']
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        user_entry = {
            "type": "transcribe",
            "prompt": "–†–∞—Å–ø–æ–∑–Ω–∞–π—Ç–µ —Ä–µ—á—å –∏–∑ —ç—Ç–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞",
            "timestamp": datetime.now().isoformat()
        }
        user_history.setdefault(user_id, []).append(user_entry)
        
        assistant_entry = {
            "type": "transcribe",
            "response": transcription,
            "timestamp": datetime.now().isoformat()
        }
        user_history[user_id].append(assistant_entry)
        save_users()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        await message.answer(f"üé§ –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:\n\n{transcription}")
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {str(e)}")
        await message.answer(
            "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:\n"
            "1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 512 MB\n"
            "2. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç MP3\n"
            "3. –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã"
        )
    
    finally:
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for root, _, files in os.walk(temp_dir):
            for file in files:
                if file.startswith(f"{file_info.file_id}."):
                    try:
                        os.remove(os.path.join(root, file))
                    except:
                        pass
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        user_transcribe_states[user_id] = None


#####################################################
# –§–∏–ª—å—Ç—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–∂–∏–¥–∞–Ω–∏—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ #
async def is_waiting_for_audio_file(message: Message):
    return user_states.get(message.from_user.id) == "waiting_for_audio_file" and \
           (message.content_type == 'audio' or message.content_type == 'voice' or message.content_type == 'document')

